name: Scrape Voicy

on:
  workflow_dispatch:  # 手動実行のみ

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    - name: チェックアウト
      uses: actions/checkout@v3
    
    - name: Pythonセットアップ
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: 依存関係インストール
      run: pip install requests beautifulsoup4
    
    - name: スクリプト作成と実行
      run: |
        # スクリプトファイル作成
        cat > voicy_scraper.py << 'EOF'
import requests
from bs4 import BeautifulSoup
import xml.etree.ElementTree as ET
from xml.dom import minidom
import datetime

# チャンネルIDを指定
channel_id = "2834"
url = f"https://voicy.jp/channel/{channel_id}/all"

# ヘッダー設定
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/91.0.4472.124'
}

# リクエスト実行
response = requests.get(url, headers=headers)
soup = BeautifulSoup(response.content, 'html.parser')

# 放送リスト用のXML作成
root = ET.Element("broadcasts")
root.set("channel_id", channel_id)
root.set("scraped_at", datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))

# 放送要素を検索
broadcast_elements = soup.select('article.episode, div.episode-item, div.broadcast-card')

# 要素が見つからない場合は別の方法を試す
if not broadcast_elements:
    # リンクから放送要素を探す
    broadcast_links = soup.select(f'a[href*="/channel/{channel_id}/"]')
    for link in broadcast_links:
        if '/all' in link.get('href', ''):
            continue
            
        broadcast_element = link.find_parent('div')
        if broadcast_element:
            # 基本情報を取得
            url = link.get('href', '')
            if url.startswith('/'):
                url = 'https://voicy.jp' + url
                
            title = link.get_text(strip=True)
            
            # XML要素作成
            broadcast_elem = ET.SubElement(root, "broadcast")
            
            # URL
            url_elem = ET.SubElement(broadcast_elem, "url")
            url_elem.text = url
            
            # タイトル
            title_elem = ET.SubElement(broadcast_elem, "title")
            title_elem.text = title
            
            # ステータス (プレミアムか無料か)
            premium_elem = broadcast_element.select_one('.premium')
            status_elem = ET.SubElement(broadcast_elem, "status")
            status_elem.text = "premium" if premium_elem else "free"

# XMLを整形して保存
xml_str = minidom.parseString(ET.tostring(root, encoding='unicode')).toprettyxml(indent="  ")
with open("voicy_data.xml", 'w', encoding='utf-8') as f:
    f.write(xml_str)

print("スクレイピング完了：voicy_data.xml に保存しました")
EOF

        # スクリプト実行
        python voicy_scraper.py
    
    - name: 結果確認
      run: |
        ls -la
        if [ -f voicy_data.xml ]; then
          echo "XMLファイルが正常に作成されました"
        else
          echo "XMLファイル作成に失敗しました"
          exit 1
        fi
        
    - name: 変更をコミット
      run: |
        git config --global user.name 'GitHub Actions'
        git config --global user.email 'actions@github.com'
        git add voicy_data.xml
        git commit -m "Voicyデータを更新" || echo "変更なし"
        git push || echo "プッシュに失敗しました"
